{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning - Monte Carlo\n",
    "If you want to test/submit your solution **restart the kernel, run all cells and submit the mc_autograde.py file into codegrade.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell imports %%execwritefile command (executes cell and writes it into file). \n",
    "# All cells that start with %%execwritefile should be in mc_autograde.py file after running all cells.\n",
    "from custommagics import CustomMagics\n",
    "get_ipython().register_magics(CustomMagics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mc_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile mc_autograde.py\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm as _tqdm\n",
    "\n",
    "def tqdm(*args, **kwargs):\n",
    "    return _tqdm(*args, **kwargs, mininterval=1)  # Safety, do not overflow buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "assert sys.version_info[:3] >= (3, 6, 0), \"Make sure you have Python 3.6 installed!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7ab207a9f93cf4d3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 1. Monte Carlo Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5f0c1d608436b67b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "For the Monte Carlo Prediction we will look at the Blackjack game (Example 5.1 from the book), for which the `BlackjackEnv` is implemented in `blackjack.py`. Note that compared to the gridworld, the state is no longer a single integer, which is why we use a dictionary to represent the value function instead of a numpy array. By using `defaultdict`, each state gets a default value of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a342b69fcfdea5b2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from blackjack import BlackjackEnv\n",
    "env = BlackjackEnv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Monte Carlo algorithm, we no longer have transition probabilities and we need to *interact* with the environment. This means that we start an episode by using `env.reset` and send the environment actions via `env.step` to observe the reward and next observation (state)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-85356add2643980e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "The main OpenAI Gym class. It encapsulates an environment with\n",
       "arbitrary behind-the-scenes dynamics. An environment can be\n",
       "partially or fully observed.\n",
       "\n",
       "The main API methods that users of this class need to know are:\n",
       "\n",
       "    step\n",
       "    reset\n",
       "    render\n",
       "    close\n",
       "    seed\n",
       "\n",
       "And set the following attributes:\n",
       "\n",
       "    action_space: The Space object corresponding to valid actions\n",
       "    observation_space: The Space object corresponding to valid observations\n",
       "    reward_range: A tuple corresponding to the min and max possible rewards\n",
       "\n",
       "Note: a default reward range set to [-inf,+inf] already exists. Set it if you want a narrower range.\n",
       "\n",
       "The methods are accessed publicly as \"step\", \"reset\", etc.. The\n",
       "non-underscored versions are wrapper methods to which we may add\n",
       "functionality over time.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/miniconda3/envs/rl/lib/python3.7/site-packages/gym/core.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     GoalEnv, Wrapper, BlackjackEnv\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# So let's have a look at what we can do in general with an environment...\n",
    "import gym\n",
    "?gym.Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-251b7b17c5d08a24",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Run one timestep of the environment's dynamics. When end of\n",
       "episode is reached, you are responsible for calling `reset()`\n",
       "to reset this environment's state.\n",
       "\n",
       "Accepts an action and returns a tuple (observation, reward, done, info).\n",
       "\n",
       "Args:\n",
       "    action (object): an action provided by the environment\n",
       "\n",
       "Returns:\n",
       "    observation (object): agent's observation of the current environment\n",
       "    reward (float) : amount of reward returned after previous action\n",
       "    done (boolean): whether the episode has ended, in which case further step() calls will return undefined results\n",
       "    info (dict): contains auxiliary diagnostic information (helpful for debugging, and sometimes learning)\n",
       "\u001b[0;31mFile:\u001b[0m      ~/OneDrive - UvA/masters/rl/exercises/2_exercise/RL_Lab2_MC_2022/blackjack.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can also look at the documentation/implementation of a method\n",
    "?env.step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6decb2ab83c5bcec",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mBlackjackEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnatural\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m        \n",
       "\u001b[0;32mclass\u001b[0m \u001b[0mBlackjackEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Simple blackjack environment\u001b[0m\n",
       "\u001b[0;34m    Blackjack is a card game where the goal is to obtain cards that sum to as\u001b[0m\n",
       "\u001b[0;34m    near as possible to 21 without going over.  They're playing against a fixed\u001b[0m\n",
       "\u001b[0;34m    dealer.\u001b[0m\n",
       "\u001b[0;34m    Face cards (Jack, Queen, King) have point value 10.\u001b[0m\n",
       "\u001b[0;34m    Aces can either count as 11 or 1, and it's called 'usable' at 11.\u001b[0m\n",
       "\u001b[0;34m    This game is placed with an infinite deck (or with replacement).\u001b[0m\n",
       "\u001b[0;34m    The game starts with each (player and dealer) having one face up and one\u001b[0m\n",
       "\u001b[0;34m    face down card.\u001b[0m\n",
       "\u001b[0;34m    The player can request additional cards (hit=1) until they decide to stop\u001b[0m\n",
       "\u001b[0;34m    (stick=0) or exceed 21 (bust).\u001b[0m\n",
       "\u001b[0;34m    After the player sticks, the dealer reveals their facedown card, and draws\u001b[0m\n",
       "\u001b[0;34m    until their sum is 17 or greater.  If the dealer goes bust the player wins.\u001b[0m\n",
       "\u001b[0;34m    If neither player nor dealer busts, the outcome (win, lose, draw) is\u001b[0m\n",
       "\u001b[0;34m    decided by whose sum is closer to 21.  The reward for winning is +1,\u001b[0m\n",
       "\u001b[0;34m    drawing is 0, and losing is -1.\u001b[0m\n",
       "\u001b[0;34m    The observation of a 3-tuple of: the players current sum,\u001b[0m\n",
       "\u001b[0;34m    the dealer's one showing card (1-10 where 1 is ace),\u001b[0m\n",
       "\u001b[0;34m    and whether or not the player holds a usable ace (0 or 1).\u001b[0m\n",
       "\u001b[0;34m    This environment corresponds to the version of the blackjack problem\u001b[0m\n",
       "\u001b[0;34m    described in Example 5.1 in Reinforcement Learning: An Introduction\u001b[0m\n",
       "\u001b[0;34m    by Sutton and Barto (1998).\u001b[0m\n",
       "\u001b[0;34m    https://webdocs.cs.ualberta.ca/~sutton/book/the-book.html\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnatural\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDiscrete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDiscrete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDiscrete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDiscrete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Flag to payout 1.5 on a \"natural\" blackjack win, like casino rules\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Ref: http://www.bicyclecards.com/how-to-play/blackjack/\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnatural\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnatural\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Start the first game\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# Number of \u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseeding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# hit: add a card to players hand and return\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdraw_card\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mis_bust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# stick: play out the dealers hand, and score\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mwhile\u001b[0m \u001b[0msum_hand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdealer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m17\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdealer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdraw_card\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdealer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnatural\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_natural\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.5\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_get_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msum_hand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdealer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musable_ace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdealer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw_hand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw_hand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Auto-draw another card if the score is less than 12\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mwhile\u001b[0m \u001b[0msum_hand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdraw_card\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m           ~/OneDrive - UvA/masters/rl/exercises/2_exercise/RL_Lab2_MC_2022/blackjack.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??BlackjackEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 1, False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ae161126d3cb1b7b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "A very simple policy for Blackjack is to *stick* if we have 20 or 21 points and *hit* otherwise. We want to know how good this policy is. This policy is *deterministic* and therefore a function that maps an observation to a single action. Technically, we can implement this as a dictionary , a function or a class with a function, where we use the last option. Moreover, it is often useful (as you will see later) to implement a function that returns  the probability $\\pi(a|s)$ for the state action pair (the probability that this policy would perform certain action in given state). We group these two functions in a policy class. To get started, let's implement this simple policy for BlackJack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9fdcb503df9cdb08",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to mc_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a mc_autograde.py\n",
    "\n",
    "class SimpleBlackjackPolicy(object):\n",
    "    \"\"\"\n",
    "    A simple BlackJack policy that sticks with 20 or 21 points and hits otherwise.\n",
    "    \"\"\"\n",
    "    def get_probs(self, states, actions):\n",
    "        \"\"\"\n",
    "        This method takes a list of states and a\n",
    "        list of actions and returns a numpy array\n",
    "        that contains a probability of perfoming\n",
    "        action in given state for every corresponding \n",
    "        state action pair. \n",
    "\n",
    "        Args:\n",
    "            states: a list of states.\n",
    "            actions: a list of actions.\n",
    "\n",
    "        Returns:\n",
    "            Numpy array filled with probabilities (same length as states and actions)\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        probs = []\n",
    "        for state, action in zip(states, actions):\n",
    "            player_sum, dealer_card, usable = state\n",
    "            # we always stick (action 0) when our sum is 20 or 21\n",
    "            if player_sum in (20, 21):\n",
    "                if action == 1:\n",
    "                    prob = 0\n",
    "                else: \n",
    "                    prob = 1\n",
    "            # we always hit (action 1) otherwise\n",
    "            else:\n",
    "                if action == 1:\n",
    "                    prob = 1\n",
    "                else:\n",
    "                    prob = 0\n",
    "            probs.append(prob)\n",
    "        return np.array(probs)\n",
    "    \n",
    "    def sample_action(self, state):\n",
    "        \"\"\"\n",
    "        This method takes a state as input and returns an action sampled from this policy.  \n",
    "\n",
    "        Args:\n",
    "            state: current state\n",
    "\n",
    "        Returns:\n",
    "            An action (int).\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        player_sum, dealer_card, usable = state\n",
    "        if player_sum < 20:\n",
    "            action = 1\n",
    "        else: \n",
    "            action = 0\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-99f02e2d9b338a5b",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: (15, 10, True)\n",
      "Sampled Action: 1\n",
      "Probabilities [stick, hit]: [0 1]\n"
     ]
    }
   ],
   "source": [
    "# Let's check if it makes sense\n",
    "env = BlackjackEnv()\n",
    "s = env.reset()\n",
    "policy = SimpleBlackjackPolicy()\n",
    "print(\"State: {}\\nSampled Action: {}\\nProbabilities [stick, hit]: {}\".format(s, policy.sample_action(s), policy.get_probs([s,s],[0,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are multiple algorithms which require data from single episode (or multiple episodes) it is often useful to write a routine that will sample a single episode. This will save us some time later. Implement a *sample_episode* function which uses environment and policy to sample a single episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to mc_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a mc_autograde.py\n",
    "\n",
    "def sample_episode(env, policy):\n",
    "    \"\"\"\n",
    "    A sampling routine. Given environment and a policy samples one episode and returns states, actions, rewards\n",
    "    and dones from environment's step function and policy's sample_action function as lists.\n",
    "\n",
    "    Args:\n",
    "        env: OpenAI gym environment.\n",
    "        policy: A policy which allows us to sample actions with its sample_action method.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of lists (states, actions, rewards, dones). All lists should have same length. \n",
    "        Hint: Do not include the state after the termination in the list of states.\n",
    "    \"\"\"\n",
    "    states = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "    dones = []\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    s = env.reset()\n",
    "    while True:\n",
    "        states.append(s)\n",
    "        a = policy.sample_action(s)\n",
    "        s, r, done, info = env.step(a)\n",
    "        actions.append(a)\n",
    "        rewards.append(r)\n",
    "        dones.append(done)\n",
    "        if done:\n",
    "            break\n",
    "    # One row will be: S_t, A_t, R_{t+1}, D_{t+1}\n",
    "    return states, actions, rewards, dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0:\n",
      "States [(19, 3, False)]\n",
      "Actions [1]\n",
      "Rewards [-1]\n",
      "Dones [True]\n",
      "\n",
      "Episode 1:\n",
      "States [(13, 7, False), (15, 7, False), (19, 7, False)]\n",
      "Actions [1, 1, 1]\n",
      "Rewards [0, 0, -1]\n",
      "Dones [False, False, True]\n",
      "\n",
      "Episode 2:\n",
      "States [(19, 1, False), (21, 1, False)]\n",
      "Actions [1, 0]\n",
      "Rewards [0, 0]\n",
      "Dones [False, True]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's sample some episodes\n",
    "env = BlackjackEnv()\n",
    "policy = SimpleBlackjackPolicy()\n",
    "for episode in range(3):\n",
    "    trajectory_data = sample_episode(env, policy)\n",
    "    print(\"Episode {}:\\nStates {}\\nActions {}\\nRewards {}\\nDones {}\\n\".format(episode,*trajectory_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0184f4c719afb98c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now implement the MC prediction algorithm (either first visit or every visit). Hint: you can use `for i in tqdm(range(num_episodes))` to show a progress bar. Use the sampling function from above to sample data from a single episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to mc_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a mc_autograde.py\n",
    "\n",
    "def mc_prediction(env, policy, num_episodes, discount_factor=1.0, sampling_function=sample_episode):\n",
    "    \"\"\"\n",
    "    Monte Carlo prediction algorithm. Calculates the value function\n",
    "    for a given policy using sampling.\n",
    "    \n",
    "    Args:\n",
    "        env: OpenAI gym environment.\n",
    "        policy: A policy which allows us to sample actions with its sample_action method.\n",
    "        num_episodes: Number of episodes to sample.\n",
    "        discount_factor: Gamma discount factor.\n",
    "        sampling_function: Function that generates data from one episode.\n",
    "    \n",
    "    Returns:\n",
    "        A dictionary that maps from state -> value.\n",
    "        The state is a tuple and the value is a float.\n",
    "    \"\"\"\n",
    "\n",
    "    # Keeps track of current V and count of returns for each state\n",
    "    # to calculate an update.\n",
    "    V = defaultdict(float)\n",
    "    returns_count = defaultdict(float)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    for i in tqdm(range(num_episodes)):\n",
    "        states, _actions, rewards, _dones = sampling_function(env, policy)\n",
    "        G = 0\n",
    "        for s, r in zip(states[::-1], rewards[::-1]):\n",
    "            G = discount_factor * G + r\n",
    "            returns_count[s] += 1\n",
    "            V[s] = V[s] + (G - V[s])/returns_count[s]  # incremental averaging\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:01<00:00, 9514.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'float'>, {(20, 10, True): 0.4285714285714286, (18, 2, False): -0.6517857142857143, (18, 2, True): -0.29411764705882354, (15, 2, True): -1.0, (15, 3, False): -0.5510204081632651, (20, 2, False): 0.5655172413793103, (19, 2, False): -0.6990291262135921, (15, 10, False): -0.6421052631578938, (20, 9, False): 0.7324840764331212, (17, 9, False): -0.5181818181818182, (18, 3, False): -0.7747747747747746, (13, 3, False): -0.2947368421052632, (19, 10, False): -0.7482517482517487, (21, 10, False): 0.8892405063291137, (12, 10, False): -0.5710382513661199, (14, 1, False): -0.7450980392156863, (12, 2, False): -0.6262626262626259, (18, 6, False): -0.6218487394957981, (13, 6, False): -0.4999999999999999, (12, 9, False): -0.35714285714285715, (21, 1, False): 0.6923076923076924, (15, 1, False): -0.6565656565656562, (13, 4, False): -0.47252747252747257, (21, 8, True): 0.9454545454545451, (14, 6, False): -0.5750000000000003, (19, 7, False): -0.794642857142857, (19, 3, False): -0.7169811320754718, (21, 2, True): 0.9245283018867925, (20, 5, False): 0.8108108108108105, (16, 5, False): -0.6842105263157893, (15, 5, False): -0.6336633663366337, (17, 2, False): -0.6823529411764704, (16, 2, False): -0.6822429906542057, (15, 2, False): -0.6989247311827954, (16, 3, False): -0.5670103092783505, (14, 3, False): -0.5454545454545455, (14, 7, False): -0.5862068965517242, (16, 6, False): -0.6608695652173909, (18, 10, False): -0.6316964285714286, (13, 10, False): -0.5833333333333333, (15, 10, True): -0.3333333333333333, (21, 10, True): 0.8916256157635466, (18, 10, True): -0.4626865671641792, (16, 10, True): -0.24561403508771934, (15, 8, False): -0.7142857142857141, (19, 6, False): -0.7272727272727274, (21, 3, False): 0.9743589743589742, (14, 9, False): -0.5760869565217391, (13, 9, False): -0.5111111111111111, (17, 1, False): -0.7692307692307698, (16, 1, False): -0.6826923076923075, (16, 10, False): -0.719211822660098, (14, 5, False): -0.5544554455445543, (20, 4, False): 0.6499999999999998, (19, 4, False): -0.7142857142857142, (18, 4, False): -0.6534653465346533, (20, 10, False): 0.4349999999999996, (14, 10, False): -0.5890410958904108, (18, 1, False): -0.781512605042017, (20, 3, False): 0.6907894736842106, (12, 5, False): -0.49425287356321834, (18, 9, False): -0.6759259259259257, (19, 8, False): -0.5619047619047617, (21, 7, False): 0.9285714285714287, (15, 7, False): -0.5283018867924529, (12, 1, False): -0.6597938144329895, (13, 2, False): -0.5825242718446604, (17, 10, False): -0.6583541147132168, (13, 8, False): -0.5446428571428573, (14, 4, False): -0.5760869565217391, (12, 3, False): -0.5238095238095237, (14, 10, True): -0.5000000000000001, (17, 4, False): -0.6504854368932035, (17, 5, False): -0.5204081632653066, (13, 5, False): -0.6395348837209301, (21, 7, True): 0.8909090909090908, (17, 3, True): -0.6, (19, 5, False): -0.6990291262135918, (18, 5, False): -0.6079999999999999, (12, 4, False): -0.5945945945945943, (20, 6, False): 0.6538461538461542, (15, 9, False): -0.6666666666666666, (21, 5, True): 0.9534883720930233, (19, 10, True): -0.3333333333333335, (12, 8, False): -0.39622641509433953, (16, 7, False): -0.5566037735849053, (13, 7, False): -0.576086956521739, (21, 5, False): 0.8717948717948718, (14, 8, False): -0.404040404040404, (21, 6, False): 0.9054054054054056, (15, 6, False): -0.6422018348623851, (20, 7, False): 0.7733333333333329, (18, 7, False): -0.810344827586207, (18, 8, False): -0.7241379310344831, (16, 8, False): -0.6486486486486487, (13, 1, False): -0.7115384615384616, (19, 7, True): -0.2631578947368421, (14, 7, True): 0.09090909090909093, (13, 7, True): 0.5384615384615384, (18, 6, True): -0.5, (17, 7, False): -0.7542372881355931, (21, 3, True): 0.857142857142857, (21, 8, False): 0.978021978021978, (21, 4, True): 0.911111111111111, (17, 3, False): -0.6382978723404252, (19, 1, False): -0.7868852459016391, (19, 1, True): -0.7222222222222223, (18, 1, True): -0.5294117647058824, (17, 6, True): -0.46153846153846156, (17, 6, False): -0.75, (13, 4, True): -0.5789473684210527, (20, 8, False): 0.7592592592592592, (19, 6, True): -0.6086956521739131, (17, 10, True): -0.4363636363636363, (20, 1, False): 0.18125, (21, 4, False): 0.847058823529412, (16, 4, True): -0.11111111111111113, (16, 4, False): -0.5420560747663552, (20, 5, True): 0.9374999999999999, (15, 4, False): -0.6603773584905659, (12, 7, False): -0.5747126436781608, (12, 6, False): -0.4166666666666668, (18, 8, True): -0.5, (20, 2, True): 0.5789473684210527, (21, 2, False): 0.8499999999999999, (14, 2, False): -0.6041666666666671, (17, 2, True): -0.42857142857142855, (21, 6, True): 0.8478260869565216, (20, 9, True): 0.7692307692307692, (17, 8, False): -0.7131147540983604, (19, 9, False): -0.7499999999999998, (13, 10, True): -0.3333333333333333, (16, 9, False): -0.6238532110091743, (19, 5, True): -0.14285714285714285, (14, 5, True): 2.7755575615628914e-17, (21, 9, False): 0.9156626506024096, (18, 9, True): -0.06666666666666667, (20, 1, True): -0.04545454545454547, (15, 3, True): -0.13333333333333336, (18, 7, True): -0.6, (14, 4, True): 0.16666666666666669, (21, 1, True): 0.7631578947368421, (12, 10, True): -0.26086956521739135, (21, 9, True): 0.9473684210526312, (14, 3, True): -0.25, (17, 9, True): -0.25, (14, 9, True): -0.1, (20, 3, True): 0.6315789473684211, (16, 9, True): -0.2692307692307692, (20, 4, True): 0.8823529411764706, (17, 4, True): 0.09090909090909093, (14, 8, True): -0.25, (13, 2, True): 0.11111111111111108, (14, 1, True): -0.33333333333333337, (16, 1, True): -0.5454545454545454, (18, 3, True): 0.19999999999999998, (12, 2, True): 0.14285714285714288, (20, 6, True): 0.75, (15, 1, True): -0.3999999999999999, (18, 5, True): -0.0769230769230769, (19, 3, True): -0.44444444444444436, (13, 1, True): -0.6666666666666666, (16, 8, True): -0.25, (13, 9, True): -0.7272727272727273, (16, 7, True): 0.0, (19, 8, True): -0.29411764705882354, (17, 1, True): -0.7, (12, 7, True): 0.25, (18, 4, True): -0.3333333333333333, (17, 5, True): -1.0, (15, 6, True): -0.5384615384615384, (14, 6, True): -0.8461538461538461, (15, 4, True): -0.15789473684210525, (20, 8, True): 0.7222222222222223, (16, 2, True): -0.3, (15, 7, True): 1.3877787807814457e-17, (13, 8, True): -0.3333333333333333, (19, 2, True): -0.5, (16, 3, True): -0.11111111111111113, (17, 7, True): 0.0, (15, 5, True): 0.14285714285714288, (19, 9, True): -0.46153846153846156, (13, 5, True): -2.7755575615628914e-17, (15, 9, True): -0.5833333333333333, (12, 9, True): 0.0, (12, 6, True): -0.4, (17, 8, True): -0.5384615384615384, (19, 4, True): -0.75, (12, 8, True): -0.42857142857142855, (13, 6, True): -0.5, (20, 7, True): 0.8749999999999999, (16, 5, True): -0.11111111111111113, (12, 5, True): 0.0, (14, 2, True): -0.25, (12, 3, True): -0.75, (16, 6, True): -0.14285714285714288, (15, 8, True): -0.6, (13, 3, True): 0.5, (12, 4, True): -1.0})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "V_10k = mc_prediction(env, SimpleBlackjackPolicy(), num_episodes=10000)\n",
    "print(V_10k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9d32f907f180c088",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now make *4 plots* like Figure 5.1 in the book. You can either make 3D plots or heatmaps. Make sure that your results look similar to the results in the book. Give your plots appropriate titles, axis labels, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cbaf4d6a0e4c00fa",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:01<00:00, 9173.89it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 500000/500000 [00:52<00:00, 9498.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.9 s, sys: 2.05 s, total: 53.9 s\n",
      "Wall time: 53.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Let's run your code one time\n",
    "V_10k = mc_prediction(env, SimpleBlackjackPolicy(), num_episodes=10000)\n",
    "V_500k = mc_prediction(env, SimpleBlackjackPolicy(), num_episodes=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ba046443478aa517",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thesofakillers/miniconda3/envs/rl/lib/python3.7/site-packages/ipykernel_launcher.py:56: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "/Users/thesofakillers/miniconda3/envs/rl/lib/python3.7/site-packages/ipykernel_launcher.py:56: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "/Users/thesofakillers/miniconda3/envs/rl/lib/python3.7/site-packages/IPython/core/pylabtools.py:151: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x800 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# helper func -----------------\n",
    "def prepare_data(value_dict):\n",
    "    # player_sum X dealer_showing\n",
    "    usable_grid = np.zeros((10, 10), dtype=float)\n",
    "    not_usable_grid = usable_grid.copy()\n",
    "\n",
    "    for s, v in value_dict.items():\n",
    "        p_sum, dealer_card, ace_usable = s\n",
    "        if ace_usable:\n",
    "            usable_grid[p_sum - 12][dealer_card - 1] = value_dict[s]\n",
    "        else:\n",
    "            not_usable_grid[p_sum - 12][dealer_card - 1] = value_dict[s]\n",
    "\n",
    "    return usable_grid, not_usable_grid\n",
    "\n",
    "\n",
    "# getting data ----------------\n",
    "usable_grid_10, not_usable_grid_10 = prepare_data(V_10k)\n",
    "usable_grid_500, not_usable_grid_500 = prepare_data(V_500k)\n",
    "\n",
    "# plotting --------------------\n",
    "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(8, 8))\n",
    "\n",
    "im = ax1.imshow(usable_grid_10, origin=\"lower\", vmin=-1, vmax=1, cmap=\"RdBu\")\n",
    "ax1.set_ylabel(\"Usable ace\")\n",
    "ax1.set_title(\"After 10,000 episodes\")\n",
    "ax1.set_yticks([])\n",
    "ax1.set_xticks([])\n",
    "\n",
    "ax2.imshow(usable_grid_500, origin=\"lower\", vmin=-1, vmax=1, cmap=\"RdBu\")\n",
    "ax2.set_title(\"After 500,000 episodes\")\n",
    "ax2.set_yticks([])\n",
    "ax2.set_xticks([])\n",
    "\n",
    "ax3.imshow(not_usable_grid_10, origin=\"lower\", vmin=-1, vmax=1, cmap=\"RdBu\")\n",
    "ax3.set_ylabel(\"No usable ace\")\n",
    "ax3.set_yticks([])\n",
    "ax3.set_xticks([])\n",
    "\n",
    "ax4.imshow(not_usable_grid_500, origin=\"lower\", vmin=-1, vmax=1, cmap=\"RdBu\")\n",
    "ax4.set_xlabel(\"Dealer Showing\")\n",
    "ax4.set_xticks(range(10))\n",
    "ax4.set_xticklabels([\"A\"] + [str(i) for i in range(2, 11)])\n",
    "ax4.set_ylabel(\"Player sum\")\n",
    "ax4.set_yticks(range(10))\n",
    "ax4.set_yticklabels(range(12, 22))\n",
    "ax4.yaxis.set_label_position(\"right\")\n",
    "ax4.yaxis.tick_right()\n",
    "\n",
    "f.set_tight_layout(True)\n",
    "\n",
    "cbar_ax = f.add_axes([1.01, 0.075, 0.03, 0.8775])\n",
    "f.colorbar(im, cax=cbar_ax, ticks=[-1, 0, 1])\n",
    "\n",
    "plt.savefig(\"../images/fig_5.1.pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Off-policy Monte Carlo prediction\n",
    "In real world, it is often beneficial to learn from the experience of others in addition to your own. For example, you can probably infer that running off the cliff with a car is a bad idea if you consider what \"return\" people who have tried it received.\n",
    "\n",
    "Similarly, we can benefit from the experience of other agents in reinforcement learning. In this exercise we will use off-policy monte carlo to estimate the value function of our target policy using the experience from a different behavior policy. Our target policy will be the simple policy defined above (stick if we have *20* or *21* points) and we will use a random policy that randomly chooses to stick or hit (both with 50% probability) as a behavior policy. As a first step, implement a random BlackJack policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to mc_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a mc_autograde.py\n",
    "\n",
    "class RandomBlackjackPolicy(object):\n",
    "    \"\"\"\n",
    "    A random BlackJack policy.\n",
    "    \"\"\"\n",
    "    def get_probs(self, states, actions):\n",
    "        \"\"\"\n",
    "        This method takes a list of states and a list of actions and returns a numpy array that contains \n",
    "        a probability of perfoming action in given state for every corresponding state action pair. \n",
    "\n",
    "        Args:\n",
    "            states: a list of states.\n",
    "            actions: a list of actions.\n",
    "\n",
    "        Returns:\n",
    "            Numpy array filled with probabilities (same length as states and actions)\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        probs = np.full(len(states), 0.5, dtype=float)\n",
    "        return probs\n",
    "    \n",
    "    def sample_action(self, state):\n",
    "        \"\"\"\n",
    "        This method takes a state as input and returns an action sampled from this policy.  \n",
    "\n",
    "        Args:\n",
    "            state: current state\n",
    "\n",
    "        Returns:\n",
    "            An action (int).\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        action = np.random.randint(low=0, high=2)  # high is exclusive\n",
    "        return action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: (18, 5, False)\n",
      "Sampled Action: 0\n",
      "Probabilities [stick, hit]: [0.5 0.5]\n"
     ]
    }
   ],
   "source": [
    "# Let's check if it makes sense\n",
    "env = BlackjackEnv()\n",
    "s = env.reset()\n",
    "policy = RandomBlackjackPolicy()\n",
    "print(\"State: {}\\nSampled Action: {}\\nProbabilities [stick, hit]: {}\".format(s, policy.sample_action(s), policy.get_probs([s,s],[0,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now implement the MC prediction algorithm with ordinary importance sampling. Use the sampling function from above to sample data from a single episode.\n",
    "\n",
    "Hint: Get probs functions may be handy. You can use `for i in tqdm(range(num_episodes))` to show a progress bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to mc_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a mc_autograde.py\n",
    "\n",
    "def mc_importance_sampling(env, behavior_policy, target_policy, num_episodes, discount_factor=1.0,\n",
    "                           sampling_function=sample_episode):\n",
    "    \"\"\"\n",
    "    Monte Carlo prediction algorithm. Calculates the value function\n",
    "    for a given target policy using behavior policy and ordinary importance sampling.\n",
    "    \n",
    "    Args:\n",
    "        env: OpenAI gym environment.\n",
    "        behavior_policy: A policy used to collect the data.\n",
    "        target_policy: A policy which value function we want to estimate.\n",
    "        num_episodes: Number of episodes to sample.\n",
    "        discount_factor: Gamma discount factor.\n",
    "        sampling_function: Function that generates data from one episode.\n",
    "    \n",
    "    Returns:\n",
    "        A dictionary that maps from state -> value.\n",
    "        The state is a tuple and the value is a float.\n",
    "    \"\"\"\n",
    "\n",
    "    # Keeps track of current V and count of returns for each state\n",
    "    # to calculate an update.\n",
    "    V = defaultdict(float)\n",
    "    returns_count = defaultdict(float)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/my/lvxg1n852nq3vf2vvjqcrzp80000gn/T/ipykernel_94093/1351262364.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mV_10k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmc_importance_sampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRandomBlackjackPolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSimpleBlackjackPolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV_10k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/my/lvxg1n852nq3vf2vvjqcrzp80000gn/T/ipykernel_94093/2765804020.py\u001b[0m in \u001b[0;36mmc_importance_sampling\u001b[0;34m(env, behavior_policy, target_policy, num_episodes, discount_factor, sampling_function)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "V_10k = mc_importance_sampling(env, RandomBlackjackPolicy(), SimpleBlackjackPolicy(), num_episodes=10000)\n",
    "print(V_10k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/var/folders/my/lvxg1n852nq3vf2vvjqcrzp80000gn/T/ipykernel_94093/2765804020.py\u001b[0m in \u001b[0;36mmc_importance_sampling\u001b[0;34m(env, behavior_policy, target_policy, num_episodes, discount_factor, sampling_function)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Let's run your code one time\n",
    "V_10k = mc_importance_sampling(env, RandomBlackjackPolicy(), SimpleBlackjackPolicy(), num_episodes=10000)\n",
    "V_500k = mc_importance_sampling(env, RandomBlackjackPolicy(), SimpleBlackjackPolicy(), num_episodes=500000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the V function. Do the plots look like what you expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/my/lvxg1n852nq3vf2vvjqcrzp80000gn/T/ipykernel_94093/2427267486.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to test/submit your solution **restart the kernel, run all cells and submit the mc_autograde.py file into codegrade.**"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
