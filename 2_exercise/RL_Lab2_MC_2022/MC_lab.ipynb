{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning - Monte Carlo\n",
    "If you want to test/submit your solution **restart the kernel, run all cells and submit the mc_autograde.py file into codegrade.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell imports %%execwritefile command (executes cell and writes it into file). \n",
    "# All cells that start with %%execwritefile should be in mc_autograde.py file after running all cells.\n",
    "from custommagics import CustomMagics\n",
    "get_ipython().register_magics(CustomMagics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mc_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile mc_autograde.py\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm as _tqdm\n",
    "\n",
    "def tqdm(*args, **kwargs):\n",
    "    return _tqdm(*args, **kwargs, mininterval=1)  # Safety, do not overflow buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "assert sys.version_info[:3] >= (3, 6, 0), \"Make sure you have Python 3.6 installed!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7ab207a9f93cf4d3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 1. Monte Carlo Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5f0c1d608436b67b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "For the Monte Carlo Prediction we will look at the Blackjack game (Example 5.1 from the book), for which the `BlackjackEnv` is implemented in `blackjack.py`. Note that compared to the gridworld, the state is no longer a single integer, which is why we use a dictionary to represent the value function instead of a numpy array. By using `defaultdict`, each state gets a default value of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a342b69fcfdea5b2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from blackjack import BlackjackEnv\n",
    "env = BlackjackEnv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Monte Carlo algorithm, we no longer have transition probabilities and we need to *interact* with the environment. This means that we start an episode by using `env.reset` and send the environment actions via `env.step` to observe the reward and next observation (state)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-85356add2643980e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "The main OpenAI Gym class. It encapsulates an environment with\n",
       "arbitrary behind-the-scenes dynamics. An environment can be\n",
       "partially or fully observed.\n",
       "\n",
       "The main API methods that users of this class need to know are:\n",
       "\n",
       "    step\n",
       "    reset\n",
       "    render\n",
       "    close\n",
       "    seed\n",
       "\n",
       "And set the following attributes:\n",
       "\n",
       "    action_space: The Space object corresponding to valid actions\n",
       "    observation_space: The Space object corresponding to valid observations\n",
       "    reward_range: A tuple corresponding to the min and max possible rewards\n",
       "\n",
       "Note: a default reward range set to [-inf,+inf] already exists. Set it if you want a narrower range.\n",
       "\n",
       "The methods are accessed publicly as \"step\", \"reset\", etc.. The\n",
       "non-underscored versions are wrapper methods to which we may add\n",
       "functionality over time.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/miniconda3/envs/rl/lib/python3.7/site-packages/gym/core.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     GoalEnv, Wrapper, BlackjackEnv\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# So let's have a look at what we can do in general with an environment...\n",
    "import gym\n",
    "?gym.Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-251b7b17c5d08a24",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Run one timestep of the environment's dynamics. When end of\n",
       "episode is reached, you are responsible for calling `reset()`\n",
       "to reset this environment's state.\n",
       "\n",
       "Accepts an action and returns a tuple (observation, reward, done, info).\n",
       "\n",
       "Args:\n",
       "    action (object): an action provided by the environment\n",
       "\n",
       "Returns:\n",
       "    observation (object): agent's observation of the current environment\n",
       "    reward (float) : amount of reward returned after previous action\n",
       "    done (boolean): whether the episode has ended, in which case further step() calls will return undefined results\n",
       "    info (dict): contains auxiliary diagnostic information (helpful for debugging, and sometimes learning)\n",
       "\u001b[0;31mFile:\u001b[0m      ~/OneDrive - UvA/masters/rl/exercises/2_exercise/RL_Lab2_MC_2022/blackjack.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can also look at the documentation/implementation of a method\n",
    "?env.step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6decb2ab83c5bcec",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mBlackjackEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnatural\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m        \n",
       "\u001b[0;32mclass\u001b[0m \u001b[0mBlackjackEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Simple blackjack environment\u001b[0m\n",
       "\u001b[0;34m    Blackjack is a card game where the goal is to obtain cards that sum to as\u001b[0m\n",
       "\u001b[0;34m    near as possible to 21 without going over.  They're playing against a fixed\u001b[0m\n",
       "\u001b[0;34m    dealer.\u001b[0m\n",
       "\u001b[0;34m    Face cards (Jack, Queen, King) have point value 10.\u001b[0m\n",
       "\u001b[0;34m    Aces can either count as 11 or 1, and it's called 'usable' at 11.\u001b[0m\n",
       "\u001b[0;34m    This game is placed with an infinite deck (or with replacement).\u001b[0m\n",
       "\u001b[0;34m    The game starts with each (player and dealer) having one face up and one\u001b[0m\n",
       "\u001b[0;34m    face down card.\u001b[0m\n",
       "\u001b[0;34m    The player can request additional cards (hit=1) until they decide to stop\u001b[0m\n",
       "\u001b[0;34m    (stick=0) or exceed 21 (bust).\u001b[0m\n",
       "\u001b[0;34m    After the player sticks, the dealer reveals their facedown card, and draws\u001b[0m\n",
       "\u001b[0;34m    until their sum is 17 or greater.  If the dealer goes bust the player wins.\u001b[0m\n",
       "\u001b[0;34m    If neither player nor dealer busts, the outcome (win, lose, draw) is\u001b[0m\n",
       "\u001b[0;34m    decided by whose sum is closer to 21.  The reward for winning is +1,\u001b[0m\n",
       "\u001b[0;34m    drawing is 0, and losing is -1.\u001b[0m\n",
       "\u001b[0;34m    The observation of a 3-tuple of: the players current sum,\u001b[0m\n",
       "\u001b[0;34m    the dealer's one showing card (1-10 where 1 is ace),\u001b[0m\n",
       "\u001b[0;34m    and whether or not the player holds a usable ace (0 or 1).\u001b[0m\n",
       "\u001b[0;34m    This environment corresponds to the version of the blackjack problem\u001b[0m\n",
       "\u001b[0;34m    described in Example 5.1 in Reinforcement Learning: An Introduction\u001b[0m\n",
       "\u001b[0;34m    by Sutton and Barto (1998).\u001b[0m\n",
       "\u001b[0;34m    https://webdocs.cs.ualberta.ca/~sutton/book/the-book.html\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnatural\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDiscrete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDiscrete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDiscrete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDiscrete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Flag to payout 1.5 on a \"natural\" blackjack win, like casino rules\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Ref: http://www.bicyclecards.com/how-to-play/blackjack/\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnatural\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnatural\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Start the first game\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# Number of \u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseeding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# hit: add a card to players hand and return\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdraw_card\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mis_bust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# stick: play out the dealers hand, and score\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mwhile\u001b[0m \u001b[0msum_hand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdealer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m17\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdealer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdraw_card\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdealer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnatural\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_natural\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.5\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_get_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msum_hand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdealer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musable_ace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdealer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw_hand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw_hand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Auto-draw another card if the score is less than 12\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mwhile\u001b[0m \u001b[0msum_hand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdraw_card\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m           ~/OneDrive - UvA/masters/rl/exercises/2_exercise/RL_Lab2_MC_2022/blackjack.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??BlackjackEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 3, True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ae161126d3cb1b7b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "A very simple policy for Blackjack is to *stick* if we have 20 or 21 points and *hit* otherwise. We want to know how good this policy is. This policy is *deterministic* and therefore a function that maps an observation to a single action. Technically, we can implement this as a dictionary , a function or a class with a function, where we use the last option. Moreover, it is often useful (as you will see later) to implement a function that returns  the probability $\\pi(a|s)$ for the state action pair (the probability that this policy would perform certain action in given state). We group these two functions in a policy class. To get started, let's implement this simple policy for BlackJack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9fdcb503df9cdb08",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to mc_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a mc_autograde.py\n",
    "\n",
    "class SimpleBlackjackPolicy(object):\n",
    "    \"\"\"\n",
    "    A simple BlackJack policy that sticks with 20 or 21 points and hits otherwise.\n",
    "    \"\"\"\n",
    "    def get_probs(self, states, actions):\n",
    "        \"\"\"\n",
    "        This method takes a list of states and a\n",
    "        list of actions and returns a numpy array\n",
    "        that contains a probability of perfoming\n",
    "        action in given state for every corresponding \n",
    "        state action pair. \n",
    "\n",
    "        Args:\n",
    "            states: a list of states.\n",
    "            actions: a list of actions.\n",
    "\n",
    "        Returns:\n",
    "            Numpy array filled with probabilities (same length as states and actions)\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        probs = []\n",
    "        for state, action in zip(states, actions):\n",
    "            player_sum, dealer_card, usable = state\n",
    "            # we always stick (action 0) when our sum is 20 or 21\n",
    "            if player_sum in (20, 21):\n",
    "                if action == 1:\n",
    "                    prob = 0\n",
    "                else: \n",
    "                    prob = 1\n",
    "            # we always hit (action 1) otherwise\n",
    "            else:\n",
    "                if action == 1:\n",
    "                    prob = 1\n",
    "                else:\n",
    "                    prob = 0\n",
    "            probs.append(prob)\n",
    "        return np.array(probs)\n",
    "    \n",
    "    def sample_action(self, state):\n",
    "        \"\"\"\n",
    "        This method takes a state as input and returns an action sampled from this policy.  \n",
    "\n",
    "        Args:\n",
    "            state: current state\n",
    "\n",
    "        Returns:\n",
    "            An action (int).\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        player_sum, dealer_card, usable = state\n",
    "        if player_sum < 20:\n",
    "            action = 1\n",
    "        else: \n",
    "            action = 0\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-99f02e2d9b338a5b",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: (14, 1, False)\n",
      "Sampled Action: 1\n",
      "Probabilities [stick, hit]: [0 1]\n"
     ]
    }
   ],
   "source": [
    "# Let's check if it makes sense\n",
    "env = BlackjackEnv()\n",
    "s = env.reset()\n",
    "policy = SimpleBlackjackPolicy()\n",
    "print(\"State: {}\\nSampled Action: {}\\nProbabilities [stick, hit]: {}\".format(s, policy.sample_action(s), policy.get_probs([s,s],[0,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are multiple algorithms which require data from single episode (or multiple episodes) it is often useful to write a routine that will sample a single episode. This will save us some time later. Implement a *sample_episode* function which uses environment and policy to sample a single episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to mc_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a mc_autograde.py\n",
    "\n",
    "def sample_episode(env, policy):\n",
    "    \"\"\"\n",
    "    A sampling routine. Given environment and a policy samples one episode and returns states, actions, rewards\n",
    "    and dones from environment's step function and policy's sample_action function as lists.\n",
    "\n",
    "    Args:\n",
    "        env: OpenAI gym environment.\n",
    "        policy: A policy which allows us to sample actions with its sample_action method.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of lists (states, actions, rewards, dones). All lists should have same length. \n",
    "        Hint: Do not include the state after the termination in the list of states.\n",
    "    \"\"\"\n",
    "    states = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "    dones = []\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    s = env.reset()\n",
    "    while True:\n",
    "        states.append(s)\n",
    "        a = policy.sample_action(s)\n",
    "        s, r, done, info = env.step(a)\n",
    "        actions.append(a)\n",
    "        rewards.append(r)\n",
    "        dones.append(done)\n",
    "        if done:\n",
    "            break\n",
    "    # One row will be: S_t, A_t, R_{t+1}, D_{t+1}\n",
    "    return states, actions, rewards, dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0:\n",
      "States [(17, 2, False)]\n",
      "Actions [1]\n",
      "Rewards [-1]\n",
      "Dones [True]\n",
      "\n",
      "Episode 1:\n",
      "States [(12, 10, False), (18, 10, False)]\n",
      "Actions [1, 1]\n",
      "Rewards [0, -1]\n",
      "Dones [False, True]\n",
      "\n",
      "Episode 2:\n",
      "States [(16, 10, False)]\n",
      "Actions [1]\n",
      "Rewards [-1]\n",
      "Dones [True]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's sample some episodes\n",
    "env = BlackjackEnv()\n",
    "policy = SimpleBlackjackPolicy()\n",
    "for episode in range(3):\n",
    "    trajectory_data = sample_episode(env, policy)\n",
    "    print(\"Episode {}:\\nStates {}\\nActions {}\\nRewards {}\\nDones {}\\n\".format(episode,*trajectory_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0184f4c719afb98c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now implement the MC prediction algorithm (either first visit or every visit). Hint: you can use `for i in tqdm(range(num_episodes))` to show a progress bar. Use the sampling function from above to sample data from a single episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to mc_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a mc_autograde.py\n",
    "\n",
    "def mc_prediction(env, policy, num_episodes, discount_factor=1.0, sampling_function=sample_episode):\n",
    "    \"\"\"\n",
    "    Monte Carlo prediction algorithm. Calculates the value function\n",
    "    for a given policy using sampling.\n",
    "    \n",
    "    Args:\n",
    "        env: OpenAI gym environment.\n",
    "        policy: A policy which allows us to sample actions with its sample_action method.\n",
    "        num_episodes: Number of episodes to sample.\n",
    "        discount_factor: Gamma discount factor.\n",
    "        sampling_function: Function that generates data from one episode.\n",
    "    \n",
    "    Returns:\n",
    "        A dictionary that maps from state -> value.\n",
    "        The state is a tuple and the value is a float.\n",
    "    \"\"\"\n",
    "\n",
    "    # Keeps track of current V and count of returns for each state\n",
    "    # to calculate an update.\n",
    "    V = defaultdict(float)\n",
    "    returns_count = defaultdict(list)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    for i in tqdm(range(num_episodes)):\n",
    "        states, _actions, rewards, _dones = sampling_function(env, policy)\n",
    "        G = 0\n",
    "        for s, r in zip(states[::-1], rewards[::-1]):\n",
    "            G = discount_factor * G + r\n",
    "            returns_count[s].append(G)\n",
    "            V[s] = np.mean(returns_count[s])\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:01<00:00, 7119.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'float'>, {(21, 10, True): 0.8591549295774648, (16, 7, False): -0.6330275229357798, (18, 3, False): -0.7961165048543689, (16, 2, False): -0.6875, (21, 8, False): 0.8918918918918919, (19, 8, False): -0.6585365853658537, (18, 8, False): -0.7777777777777778, (20, 5, False): 0.6778523489932886, (12, 5, False): -0.3958333333333333, (16, 9, False): -0.5673076923076923, (17, 9, True): -0.5, (21, 10, False): 0.8935483870967742, (14, 10, False): -0.7038043478260869, (17, 9, False): -0.6456692913385826, (17, 8, False): -0.6428571428571429, (15, 10, False): -0.7100737100737101, (21, 6, True): 0.9302325581395349, (18, 6, True): -0.2962962962962963, (16, 6, True): -0.35294117647058826, (20, 10, False): 0.3952702702702703, (19, 10, False): -0.782608695652174, (19, 10, True): -0.5194805194805194, (18, 10, False): -0.6988235294117647, (13, 10, False): -0.6430446194225722, (13, 10, True): 0.08823529411764706, (19, 4, False): -0.6864406779661016, (20, 9, False): 0.7701863354037267, (12, 10, False): -0.5526315789473685, (16, 6, False): -0.6185567010309279, (12, 6, False): -0.4883720930232558, (17, 4, False): -0.7978723404255319, (21, 8, True): 0.8936170212765957, (15, 5, False): -0.6336633663366337, (19, 9, False): -0.8188976377952756, (13, 8, False): -0.6111111111111112, (16, 10, False): -0.6415094339622641, (19, 6, False): -0.8130081300813008, (13, 6, False): -0.5471698113207547, (15, 6, False): -0.6210526315789474, (20, 4, False): 0.6910112359550562, (17, 10, False): -0.7233502538071066, (12, 3, False): -0.4722222222222222, (21, 2, False): 0.8850574712643678, (21, 5, False): 0.9142857142857143, (19, 1, False): -0.6967213114754098, (16, 10, True): -0.3269230769230769, (16, 4, False): -0.5384615384615384, (13, 4, False): -0.5833333333333334, (18, 9, False): -0.7, (17, 4, True): -0.3076923076923077, (21, 1, True): 0.5964912280701754, (19, 1, True): -0.2631578947368421, (12, 2, False): -0.48863636363636365, (16, 1, False): -0.7425742574257426, (13, 2, False): -0.6022727272727273, (20, 2, False): 0.5639097744360902, (21, 3, False): 0.927536231884058, (21, 7, False): 0.9156626506024096, (19, 7, False): -0.7424242424242424, (12, 7, False): -0.46464646464646464, (12, 9, False): -0.5897435897435898, (17, 7, False): -0.7876106194690266, (20, 8, False): 0.6891891891891891, (12, 8, False): -0.5851063829787234, (17, 2, False): -0.5636363636363636, (14, 5, False): -0.5730337078651685, (16, 8, False): -0.5212765957446809, (15, 8, False): -0.7676767676767676, (17, 1, False): -0.7272727272727273, (17, 1, True): -0.6153846153846154, (14, 1, True): -0.6470588235294118, (21, 4, False): 0.8536585365853658, (19, 2, False): -0.6761904761904762, (18, 2, False): -0.6915887850467289, (18, 7, True): -0.5555555555555556, (17, 7, True): -0.5384615384615384, (15, 2, False): -0.6213592233009708, (15, 2, True): -0.2, (15, 9, False): -0.5483870967741935, (14, 1, False): -0.6578947368421053, (17, 6, False): -0.646551724137931, (21, 6, False): 0.8764044943820225, (14, 6, False): -0.4807692307692308, (13, 3, False): -0.5161290322580645, (20, 6, False): 0.7318840579710145, (12, 4, False): -0.4811320754716981, (14, 2, False): -0.5161290322580645, (20, 1, False): 0.1895424836601307, (15, 7, False): -0.6339285714285714, (13, 5, False): -0.4772727272727273, (14, 9, False): -0.4444444444444444, (20, 8, True): 0.6296296296296297, (19, 8, True): -0.3888888888888889, (21, 4, True): 0.9074074074074074, (18, 10, True): -0.3968253968253968, (12, 1, False): -0.6310679611650486, (20, 7, False): 0.7758620689655172, (20, 3, False): 0.5753424657534246, (13, 1, False): -0.6170212765957447, (18, 6, False): -0.7, (21, 1, False): 0.6024096385542169, (18, 1, False): -0.7924528301886793, (18, 4, False): -0.580952380952381, (16, 5, False): -0.6666666666666666, (14, 8, False): -0.6976744186046512, (14, 8, True): -0.6, (20, 10, True): 0.4868421052631579, (21, 3, True): 0.8222222222222222, (19, 5, False): -0.8415841584158416, (21, 9, True): 0.926829268292683, (15, 9, True): -0.09090909090909091, (21, 5, True): 0.9411764705882353, (21, 7, True): 0.96, (14, 7, True): -0.7142857142857143, (15, 1, False): -0.6086956521739131, (17, 3, False): -0.7727272727272727, (21, 9, False): 0.9305555555555556, (19, 3, False): -0.8, (15, 8, True): -0.1111111111111111, (15, 4, False): -0.6526315789473685, (14, 7, False): -0.6517857142857143, (17, 5, False): -0.719626168224299, (16, 3, False): -0.75, (13, 2, True): -0.5, (14, 10, True): -0.18421052631578946, (17, 10, True): -0.16071428571428573, (15, 3, False): -0.5619047619047619, (18, 4, True): 0.3888888888888889, (16, 8, True): -0.29411764705882354, (14, 4, False): -0.47474747474747475, (13, 7, False): -0.78125, (20, 6, True): 0.8571428571428571, (13, 9, False): -0.5520833333333334, (16, 9, True): -0.6, (12, 9, True): 0.2, (18, 8, True): -0.6470588235294118, (15, 1, True): -0.3333333333333333, (18, 7, False): -0.62, (16, 2, True): -0.2, (18, 5, False): -0.7614678899082569, (15, 3, True): -0.42105263157894735, (17, 3, True): -0.5, (18, 9, True): -0.2, (12, 8, True): -0.5, (20, 4, True): 0.5555555555555556, (18, 3, True): -0.7777777777777778, (14, 3, False): -0.7115384615384616, (13, 8, True): -0.125, (17, 2, True): -0.8181818181818182, (18, 1, True): -1.0, (20, 2, True): 0.8666666666666667, (19, 2, True): -0.7647058823529411, (12, 2, True): 0.6, (19, 6, True): -0.625, (13, 6, True): -0.06666666666666667, (14, 3, True): 0.0, (14, 2, True): 0.2, (14, 4, True): 0.16666666666666666, (20, 1, True): 0.1111111111111111, (17, 8, True): -0.23076923076923078, (20, 3, True): 0.5, (13, 3, True): -0.8, (12, 7, True): -0.3333333333333333, (15, 10, True): -0.6, (19, 5, True): -0.8461538461538461, (17, 5, True): -0.8125, (14, 6, True): -0.4, (20, 7, True): 0.6875, (16, 5, True): -0.45454545454545453, (16, 1, True): -0.46153846153846156, (21, 2, True): 0.9090909090909091, (16, 4, True): -0.5333333333333333, (13, 1, True): -0.5714285714285714, (15, 7, True): 0.0, (16, 7, True): -0.47368421052631576, (20, 9, True): 0.6363636363636364, (20, 5, True): 0.6111111111111112, (19, 7, True): -0.4666666666666667, (18, 2, True): -0.5384615384615384, (12, 10, True): -0.23076923076923078, (16, 3, True): -0.2857142857142857, (13, 4, True): 0.0, (19, 9, True): -0.3333333333333333, (13, 5, True): -0.4, (17, 6, True): -0.4, (12, 3, True): -0.2, (13, 7, True): -0.2, (19, 3, True): -0.3125, (14, 5, True): -0.3333333333333333, (14, 9, True): -0.5, (12, 6, True): 0.0, (15, 5, True): 0.0, (15, 6, True): 0.0, (15, 4, True): -0.4, (12, 4, True): 0.3333333333333333, (18, 5, True): -0.6, (19, 4, True): -0.1111111111111111, (13, 9, True): -0.25, (12, 5, True): 0.2, (12, 1, True): -0.5})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "V_10k = mc_prediction(env, SimpleBlackjackPolicy(), num_episodes=10000)\n",
    "print(V_10k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9d32f907f180c088",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now make *4 plots* like Figure 5.1 in the book. You can either make 3D plots or heatmaps. Make sure that your results look similar to the results in the book. Give your plots appropriate titles, axis labels, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cbaf4d6a0e4c00fa",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:01<00:00, 7345.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 500000/500000 [08:55<00:00, 932.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 46s, sys: 5.06 s, total: 8min 51s\n",
      "Wall time: 8min 57s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Let's run your code one time\n",
    "V_10k = mc_prediction(env, SimpleBlackjackPolicy(), num_episodes=10000)\n",
    "V_500k = mc_prediction(env, SimpleBlackjackPolicy(), num_episodes=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ba046443478aa517",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x800 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# helper func -----------------\n",
    "def prepare_data(value_dict):\n",
    "    # player_sum X dealer_showing\n",
    "    usable_grid = np.zeros((10, 10), dtype=float)\n",
    "    not_usable_grid = usable_grid.copy()\n",
    "\n",
    "    for s, v in value_dict.items():\n",
    "        p_sum, dealer_card, ace_usable = s\n",
    "        if ace_usable:\n",
    "            usable_grid[p_sum - 12][dealer_card - 1] = value_dict[s]\n",
    "        else:\n",
    "            not_usable_grid[p_sum - 12][dealer_card - 1] = value_dict[s]\n",
    "\n",
    "    return usable_grid, not_usable_grid\n",
    "\n",
    "\n",
    "# getting data ----------------\n",
    "usable_grid_10, not_usable_grid_10 = prepare_data(V_10k)\n",
    "usable_grid_500, not_usable_grid_500 = prepare_data(V_500k)\n",
    "\n",
    "# plotting --------------------\n",
    "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(8, 8))\n",
    "\n",
    "im = ax1.imshow(usable_grid_10, origin=\"lower\", vmin=-1, vmax=1, cmap=\"RdBu\")\n",
    "ax1.set_ylabel(\"Usable ace\")\n",
    "ax1.set_title(\"After 10,000 episodes\")\n",
    "ax1.set_yticks([])\n",
    "ax1.set_xticks([])\n",
    "\n",
    "ax2.imshow(usable_grid_500, origin=\"lower\", vmin=-1, vmax=1, cmap=\"RdBu\")\n",
    "ax2.set_title(\"After 500,000 episodes\")\n",
    "ax2.set_yticks([])\n",
    "ax2.set_xticks([])\n",
    "\n",
    "ax3.imshow(not_usable_grid_10, origin=\"lower\", vmin=-1, vmax=1, cmap=\"RdBu\")\n",
    "ax3.set_ylabel(\"No usable ace\")\n",
    "ax3.set_yticks([])\n",
    "ax3.set_xticks([])\n",
    "\n",
    "ax4.imshow(not_usable_grid_500, origin=\"lower\", vmin=-1, vmax=1, cmap=\"RdBu\")\n",
    "ax4.set_xlabel(\"Dealer Showing\")\n",
    "ax4.set_xticks(range(10))\n",
    "ax4.set_xticklabels([\"A\"] + [str(i) for i in range(2, 11)])\n",
    "ax4.set_ylabel(\"Player sum\")\n",
    "ax4.set_yticks(range(10))\n",
    "ax4.set_yticklabels(range(12, 22))\n",
    "ax4.yaxis.set_label_position(\"right\")\n",
    "ax4.yaxis.tick_right()\n",
    "\n",
    "f.set_tight_layout(True)\n",
    "\n",
    "cbar_ax = f.add_axes([1.01, 0.08, 0.03, 0.875])\n",
    "f.colorbar(im, cax=cbar_ax, ticks=[-1, 0, 1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Off-policy Monte Carlo prediction\n",
    "In real world, it is often beneficial to learn from the experience of others in addition to your own. For example, you can probably infer that running off the cliff with a car is a bad idea if you consider what \"return\" people who have tried it received.\n",
    "\n",
    "Similarly, we can benefit from the experience of other agents in reinforcement learning. In this exercise we will use off-policy monte carlo to estimate the value function of our target policy using the experience from a different behavior policy. Our target policy will be the simple policy defined above (stick if we have *20* or *21* points) and we will use a random policy that randomly chooses to stick or hit (both with 50% probability) as a behavior policy. As a first step, implement a random BlackJack policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to mc_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a mc_autograde.py\n",
    "\n",
    "class RandomBlackjackPolicy(object):\n",
    "    \"\"\"\n",
    "    A random BlackJack policy.\n",
    "    \"\"\"\n",
    "    def get_probs(self, states, actions):\n",
    "        \"\"\"\n",
    "        This method takes a list of states and a list of actions and returns a numpy array that contains \n",
    "        a probability of perfoming action in given state for every corresponding state action pair. \n",
    "\n",
    "        Args:\n",
    "            states: a list of states.\n",
    "            actions: a list of actions.\n",
    "\n",
    "        Returns:\n",
    "            Numpy array filled with probabilities (same length as states and actions)\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError\n",
    "        return probs\n",
    "    \n",
    "    def sample_action(self, state):\n",
    "        \"\"\"\n",
    "        This method takes a state as input and returns an action sampled from this policy.  \n",
    "\n",
    "        Args:\n",
    "            state: current state\n",
    "\n",
    "        Returns:\n",
    "            An action (int).\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError\n",
    "        return action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/my/lvxg1n852nq3vf2vvjqcrzp80000gn/T/ipykernel_61114/1012020966.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpolicy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomBlackjackPolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"State: {}\\nSampled Action: {}\\nProbabilities [stick, hit]: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/my/lvxg1n852nq3vf2vvjqcrzp80000gn/T/ipykernel_61114/3068290644.py\u001b[0m in \u001b[0;36msample_action\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \"\"\"\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Let's check if it makes sense\n",
    "env = BlackjackEnv()\n",
    "s = env.reset()\n",
    "policy = RandomBlackjackPolicy()\n",
    "print(\"State: {}\\nSampled Action: {}\\nProbabilities [stick, hit]: {}\".format(s, policy.sample_action(s), policy.get_probs([s,s],[0,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now implement the MC prediction algorithm with ordinary importance sampling. Use the sampling function from above to sample data from a single episode.\n",
    "\n",
    "Hint: Get probs functions may be handy. You can use `for i in tqdm(range(num_episodes))` to show a progress bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to mc_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a mc_autograde.py\n",
    "\n",
    "def mc_importance_sampling(env, behavior_policy, target_policy, num_episodes, discount_factor=1.0,\n",
    "                           sampling_function=sample_episode):\n",
    "    \"\"\"\n",
    "    Monte Carlo prediction algorithm. Calculates the value function\n",
    "    for a given target policy using behavior policy and ordinary importance sampling.\n",
    "    \n",
    "    Args:\n",
    "        env: OpenAI gym environment.\n",
    "        behavior_policy: A policy used to collect the data.\n",
    "        target_policy: A policy which value function we want to estimate.\n",
    "        num_episodes: Number of episodes to sample.\n",
    "        discount_factor: Gamma discount factor.\n",
    "        sampling_function: Function that generates data from one episode.\n",
    "    \n",
    "    Returns:\n",
    "        A dictionary that maps from state -> value.\n",
    "        The state is a tuple and the value is a float.\n",
    "    \"\"\"\n",
    "\n",
    "    # Keeps track of current V and count of returns for each state\n",
    "    # to calculate an update.\n",
    "    V = defaultdict(float)\n",
    "    returns_count = defaultdict(float)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/my/lvxg1n852nq3vf2vvjqcrzp80000gn/T/ipykernel_61114/1351262364.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mV_10k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmc_importance_sampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRandomBlackjackPolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSimpleBlackjackPolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV_10k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/my/lvxg1n852nq3vf2vvjqcrzp80000gn/T/ipykernel_61114/2765804020.py\u001b[0m in \u001b[0;36mmc_importance_sampling\u001b[0;34m(env, behavior_policy, target_policy, num_episodes, discount_factor, sampling_function)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "V_10k = mc_importance_sampling(env, RandomBlackjackPolicy(), SimpleBlackjackPolicy(), num_episodes=10000)\n",
    "print(V_10k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/var/folders/my/lvxg1n852nq3vf2vvjqcrzp80000gn/T/ipykernel_61114/2765804020.py\u001b[0m in \u001b[0;36mmc_importance_sampling\u001b[0;34m(env, behavior_policy, target_policy, num_episodes, discount_factor, sampling_function)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Let's run your code one time\n",
    "V_10k = mc_importance_sampling(env, RandomBlackjackPolicy(), SimpleBlackjackPolicy(), num_episodes=10000)\n",
    "V_500k = mc_importance_sampling(env, RandomBlackjackPolicy(), SimpleBlackjackPolicy(), num_episodes=500000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the V function. Do the plots look like what you expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/my/lvxg1n852nq3vf2vvjqcrzp80000gn/T/ipykernel_61114/2427267486.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to test/submit your solution **restart the kernel, run all cells and submit the mc_autograde.py file into codegrade.**"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
