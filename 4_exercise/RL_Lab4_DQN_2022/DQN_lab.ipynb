{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning - Deep Q Network\n",
    "If you want to test/submit your solution **restart the kernel, run all cells and submit the dqn_autograde.py file into codegrade.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custommagics import CustomMagics\n",
    "\n",
    "get_ipython().register_magics(CustomMagics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dqn_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile dqn_autograde.py\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from tqdm import tqdm as _tqdm\n",
    "\n",
    "\n",
    "def tqdm(*args, **kwargs):\n",
    "    return _tqdm(*args, **kwargs, mininterval=1)  # Safety, do not overflow buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fc69f22067705372",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import time\n",
    "\n",
    "assert sys.version_info[:3] >= (3, 6, 0), \"Make sure you have Python 3.6 installed!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fef7e20e54e6243b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 1. Deep Q-Network (DQN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-39519f4ab05eb2a1",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thesofakillers/miniconda3/envs/rl/lib/python3.7/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.envs.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m        CartPoleEnv\n",
       "\u001b[0;31mString form:\u001b[0m <CartPoleEnv<CartPole-v1>>\n",
       "\u001b[0;31mFile:\u001b[0m        ~/miniconda3/envs/rl/lib/python3.7/site-packages/gym/envs/classic_control/cartpole.py\n",
       "\u001b[0;31mSource:\u001b[0m     \n",
       "\u001b[0;32mclass\u001b[0m \u001b[0mCartPoleEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"\u001b[0m\n",
       "\u001b[0;34m    Description:\u001b[0m\n",
       "\u001b[0;34m        A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. The pendulum starts upright, and the goal is to prevent it from falling over by increasing and reducing the cart's velocity.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Source:\u001b[0m\n",
       "\u001b[0;34m        This environment corresponds to the version of the cart-pole problem described by Barto, Sutton, and Anderson\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Observation: \u001b[0m\n",
       "\u001b[0;34m        Type: Box(4)\u001b[0m\n",
       "\u001b[0;34m        Num     Observation                 Min         Max\u001b[0m\n",
       "\u001b[0;34m        0       Cart Position             -4.8            4.8\u001b[0m\n",
       "\u001b[0;34m        1       Cart Velocity             -Inf            Inf\u001b[0m\n",
       "\u001b[0;34m        2       Pole Angle                 -24°           24°\u001b[0m\n",
       "\u001b[0;34m        3       Pole Velocity At Tip      -Inf            Inf\u001b[0m\n",
       "\u001b[0;34m        \u001b[0m\n",
       "\u001b[0;34m    Actions:\u001b[0m\n",
       "\u001b[0;34m        Type: Discrete(2)\u001b[0m\n",
       "\u001b[0;34m        Num     Action\u001b[0m\n",
       "\u001b[0;34m        0       Push cart to the left\u001b[0m\n",
       "\u001b[0;34m        1       Push cart to the right\u001b[0m\n",
       "\u001b[0;34m        \u001b[0m\n",
       "\u001b[0;34m        Note: The amount the velocity is reduced or increased is not fixed as it depends on the angle the pole is pointing. This is because the center of gravity of the pole increases the amount of energy needed to move the cart underneath it\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Reward:\u001b[0m\n",
       "\u001b[0;34m        Reward is 1 for every step taken, including the termination step\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Starting State:\u001b[0m\n",
       "\u001b[0;34m        All observations are assigned a uniform random value between ±0.05\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Episode Termination:\u001b[0m\n",
       "\u001b[0;34m        Pole Angle is more than ±12°\u001b[0m\n",
       "\u001b[0;34m        Cart Position is more than ±2.4 (center of the cart reaches the edge of the display)\u001b[0m\n",
       "\u001b[0;34m        Episode length is greater than 200\u001b[0m\n",
       "\u001b[0;34m        Solved Requirements\u001b[0m\n",
       "\u001b[0;34m        Considered solved when the average reward is greater than or equal to 195.0 over 100 consecutive trials.\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m'render.modes'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m'video.frames_per_second'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgravity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m9.8\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasscart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasspole\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_mass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasspole\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasscart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;31m# actually half the pole's length\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolemass_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasspole\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_mag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10.0\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.02\u001b[0m  \u001b[0;31m# seconds between state updates\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkinematics_integrator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'euler'\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Angle at which to fail the episode\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta_threshold_radians\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m360\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2.4\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Angle limit set to 2 * theta_threshold_radians so failing observation is still within bounds\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mhigh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_threshold\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta_threshold_radians\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDiscrete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseeding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%r (%s) invalid\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_dot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mforce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_mag\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_mag\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mcostheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msintheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforce\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolemass_length\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msintheta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_mass\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mthetaacc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgravity\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msintheta\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcostheta\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasspole\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcostheta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcostheta\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_mass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mxacc\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolemass_length\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mthetaacc\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcostheta\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_mass\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkinematics_integrator\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'euler'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mx\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_dot\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mx_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_dot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mxacc\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtheta_dot\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtheta_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mthetaacc\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# semi-implicit euler\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mx_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_dot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mxacc\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mx\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_dot\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtheta_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mthetaacc\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtheta_dot\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_dot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta_dot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_threshold\u001b[0m \\\n",
       "                \u001b[0;32mor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_threshold\u001b[0m \\\n",
       "                \u001b[0;32mor\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta_threshold_radians\u001b[0m \\\n",
       "                \u001b[0;32mor\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta_threshold_radians\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# Pole just fell!\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mscreen_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mscreen_height\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mworld_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_threshold\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscreen_width\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mworld_width\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mcarty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;31m# TOP OF CART\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mpolewidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10.0\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mpolelen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mcartwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50.0\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mcartheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30.0\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassic_control\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mViewer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcartwidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcartwidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcartheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcartheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0maxleoffset\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mcartheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m4.0\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mcart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFilledPolygon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcarttrans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mcart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcarttrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_geom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mpolewidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpolewidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpolelen\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpolewidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpolewidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mpole\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFilledPolygon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mpole\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoletrans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxleoffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mpole\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoletrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mpole\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcarttrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_geom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_circle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolewidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoletrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcarttrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_geom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcarty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcarty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_geom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mcartx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2.0\u001b[0m \u001b[0;31m# MIDDLE OF CART\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcarttrans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_translation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcartx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcarty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoletrans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_rotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_rgb_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# env is a TimeLimit wrapper around an env, so use env.env to look into the env (but otherwise you can forget about this)\n",
    "??env.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The nice thing about the CARTPOLE is that it has very nice rendering functionality (if you are on a local environment). Let's have a look at an episode\n",
    "obs = env.reset()\n",
    "env.render()\n",
    "done = False\n",
    "while not done:\n",
    "    obs, reward, done, _ = env.step(env.action_space.sample())\n",
    "    env.render()\n",
    "    time.sleep(0.05)\n",
    "env.close()  # Close the environment or you will have a lot of render screens soon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2d83f70e62b99520",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Remember from the previous lab, that in order to optimize a policy we need to estimate the Q-values (e.g. estimate the *action* values). In the CartPole problem, our state is current position of the cart, the current velocity of the cart, the current (angular) position of the pole and the (angular) speed of the pole. As these are continuous variables, we have an infinite number of states (ignoring the fact that a digital computer can only represent finitely many states in finite memory)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0b3162496f5e6cf5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.1 Implement Q-Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-96a86bcfa1ebc84a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "We will not use the tabular approach but approximate the Q-value function by a general approximator function. We will skip the linear case and directly use a two layer Neural Network. We use [PyTorch](https://pytorch.org/) to implement the network, as this will allow us to train it easily later. We can implement a model using `torch.nn.Sequential`, but with PyTorch it is actually very easy to implement the model (e.g. the forward pass) from scratch. Now implement the `QNetwork.forward` function that uses one hidden layer with ReLU activation (no output activation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-216429a5dccf8a0e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to dqn_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a dqn_autograde.py\n",
    "\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, num_hidden=128):\n",
    "        nn.Module.__init__(self)\n",
    "        self.l1 = nn.Linear(4, num_hidden)\n",
    "        self.l2 = nn.Linear(num_hidden, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # YOUR CODE HERE\n",
    "        x = self.l1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.l2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-00ce108d640a5942",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's instantiate and test if it works\n",
    "num_hidden = 128\n",
    "torch.manual_seed(1)\n",
    "Q_net = QNetwork(num_hidden)\n",
    "\n",
    "torch.manual_seed(1)\n",
    "test_model = nn.Sequential(\n",
    "    nn.Linear(4, num_hidden), nn.ReLU(), nn.Linear(num_hidden, 2)\n",
    ")\n",
    "\n",
    "x = torch.rand(10, 4)\n",
    "\n",
    "# If you do not need backpropagation, wrap the computation in the torch.no_grad() context\n",
    "# This saves time and memory, and PyTorch complaints when converting to numpy\n",
    "with torch.no_grad():\n",
    "    assert np.allclose(Q_net(x).numpy(), test_model(x).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ca77eae2e62180cf",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.2 Experience Replay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2c1d117a1a75fd69",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "In order to stabilize learning, we will use an experience replay to save states in and sample states from. Now implement the `push` function that adds a transition to the replay buffer, and the `sample` function that samples a (random!) batch of data, for use during training (hint: you can use the function `random.sample`). It should keep at most the maximum number of transitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a3cc876e51eb157f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to dqn_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a dqn_autograde.py\n",
    "\n",
    "\n",
    "class ReplayMemory:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "\n",
    "    def push(self, transition):\n",
    "        # YOUR CODE HERE\n",
    "        self.memory.append(transition)\n",
    "        self.memory = self.memory[-self.capacity:]\n",
    "            \n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        # YOUR CODE HERE\n",
    "        return random.sample(self.memory, batch_size)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3b90135921c4da76",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(array([-0.04255671, -0.00115242,  0.00569409, -0.00483693]), 0, 1.0, array([-0.04257976, -0.19635556,  0.00559735,  0.28963709]), False)]\n"
     ]
    }
   ],
   "source": [
    "capacity = 10\n",
    "memory = ReplayMemory(capacity)\n",
    "\n",
    "# Sample a transition\n",
    "s = env.reset()\n",
    "a = env.action_space.sample()\n",
    "s_next, r, done, _ = env.step(a)\n",
    "\n",
    "# Push a transition\n",
    "memory.push((s, a, r, s_next, done))\n",
    "\n",
    "# Sample a batch size of 1\n",
    "print(memory.sample(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-88f67e3c051da6a9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.3 $\\epsilon$psilon greedy policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-aa3c7d1b3000f697",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "In order to learn a good policy, we need to explore quite a bit initially. As we start to learn a good policy, we want to decrease the exploration. As the amount of exploration using an $\\epsilon$-greedy policy is controlled by $\\epsilon$, we can define an 'exploration scheme' by writing $\\epsilon$ as a function of time. There are many possible schemes, but we will use a simple one: we will start with only exploring (so taking random actions) at iteration 0, and then in 1000 iterations linearly anneal $\\epsilon$ such that after 1000 iterations we take random (exploration) actions with 5\\% probability (forever, as you never know if the environment will change)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5789e7a792108576",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to dqn_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a dqn_autograde.py\n",
    "\n",
    "\n",
    "def get_epsilon(it):\n",
    "    # YOUR CODE HERE\n",
    "    if it <= 1000:\n",
    "        epsilon = -0.00095*it + 1\n",
    "    else:\n",
    "        epsilon = 0.05\n",
    "    return epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-40e66db45e742b2e",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9dcb9b3b10>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# So what's an easy way to check?\n",
    "plt.plot([get_epsilon(it) for it in range(5000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a8b604c9998c6c3b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now write a function of *EpsilonGreedyPolicy* class. This function takes a state and uses the Q-network to select an ($\\epsilon$-greedy) action. It should return a random action with probability epsilon. Note, you do not need to backpropagate through the model computations, so use `with torch.no_grad():` (see above for example). Note that to convert a PyTorch tensor with only 1 element (0 dimensional) to a simple python scalar (int or float), you can use the '.item()' function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-878ad3a637cfb51c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to dqn_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a dqn_autograde.py\n",
    "\n",
    "\n",
    "class EpsilonGreedyPolicy(object):\n",
    "    \"\"\"\n",
    "    A simple epsilon greedy policy.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, Q, epsilon):\n",
    "        self.Q = Q\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def sample_action(self, obs):\n",
    "        \"\"\"\n",
    "        This method takes a state as input and returns an action sampled from this policy.\n",
    "\n",
    "        Args:\n",
    "            obs: current state\n",
    "\n",
    "        Returns:\n",
    "            An action (int).\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        with torch.no_grad():\n",
    "            obs = torch.tensor(obs.astype(np.float32))\n",
    "            q_values = self.Q(obs)\n",
    "            n_actions = q_values.size(-1)\n",
    "            greedily = np.random.choice(\n",
    "                a=2,\n",
    "                size=1,\n",
    "                replace=True,\n",
    "                # non-greedily: epsilon, greedily: 1-epsilon\n",
    "                p=[self.epsilon, 1 - self.epsilon],\n",
    "            ).astype(bool)\n",
    "            if greedily:\n",
    "                action = q_values.argmax().item()\n",
    "            else:\n",
    "                action = np.random.randint(0, n_actions)\n",
    "            return action\n",
    "\n",
    "    def set_epsilon(self, epsilon):\n",
    "        self.epsilon = epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e895338d56bee477",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "s = env.reset()\n",
    "epg = EpsilonGreedyPolicy(Q_net, 0.05)\n",
    "a = epg.sample_action(s)\n",
    "assert not torch.is_tensor(a)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ec5e94e0b03f8aec",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.4 Training function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d1a12cc97386fe56",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now we will implement the function 'train' that samples a batch from the memory and performs a gradient step using some convenient PyTorch functionality. However, you still need to compute the Q-values for the (state, action) pairs in the experience, as well as their target (e.g. the value they should move towards). What is the target for a Q-learning update? What should be the target if `next_state` is terminal (e.g. `done`)?\n",
    "\n",
    "For computing the Q-values for the actions, note that the model returns all action values where you are only interested in a single action value. Because of the batch dimension, you can't use simple indexing, but you may want to have a look at [torch.gather](https://pytorch.org/docs/stable/torch.html?highlight=gather#torch.gather) or use [advanced indexing](https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.indexing.html) (numpy tutorial but works mostly the same in PyTorch). Note, you should NOT modify the function train. You can view the size of a tensor `x` with `x.size()` (similar to `x.shape` in numpy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6c45485324b40081",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to dqn_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a dqn_autograde.py\n",
    "\n",
    "\n",
    "def compute_q_vals(Q, states, actions):\n",
    "    \"\"\"\n",
    "    This method returns Q values for given state action pairs.\n",
    "\n",
    "    Args:\n",
    "        Q: Q-net\n",
    "        states: a tensor of states. Shape: batch_size x obs_dim\n",
    "        actions: a tensor of actions. Shape: Shape: batch_size x 1\n",
    "\n",
    "    Returns:\n",
    "        A torch tensor filled with Q values. Shape: batch_size x 1.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    q_vals = Q(states).gather(1, actions)\n",
    "    return q_vals\n",
    "\n",
    "def compute_targets(Q, rewards, next_states, dones, discount_factor):\n",
    "    \"\"\"\n",
    "    This method returns targets (values towards which Q-values should move).\n",
    "\n",
    "    Args:\n",
    "        Q: Q-net\n",
    "        rewards: a tensor of rewards. Shape: Shape: batch_size x 1\n",
    "        next_states: a tensor of states. Shape: batch_size x obs_dim\n",
    "        dones: a tensor of boolean done flags (indicates if next_state is terminal) Shape: batch_size x 1\n",
    "        discount_factor: discount\n",
    "    Returns:\n",
    "        A torch tensor filled with target values. Shape: batch_size x 1.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    targets = rewards + discount_factor * Q(next_states).max(1)[0].unsqueeze(1) * (1 - dones.float())\n",
    "    return targets\n",
    "\n",
    "\n",
    "def train(Q, memory, optimizer, batch_size, discount_factor):\n",
    "    # DO NOT MODIFY THIS FUNCTION\n",
    "\n",
    "    # don't learn without some decent experience\n",
    "    if len(memory) < batch_size:\n",
    "        return None\n",
    "\n",
    "    # random transition batch is taken from experience replay memory\n",
    "    transitions = memory.sample(batch_size)\n",
    "\n",
    "    # transition is a list of 4-tuples, instead we want 4 vectors (as torch.Tensor's)\n",
    "    state, action, reward, next_state, done = zip(*transitions)\n",
    "\n",
    "    # convert to PyTorch and define types\n",
    "    state = torch.tensor(state, dtype=torch.float)\n",
    "    action = torch.tensor(action, dtype=torch.int64)[\n",
    "        :, None\n",
    "    ]  # Need 64 bit to use them as index\n",
    "    next_state = torch.tensor(next_state, dtype=torch.float)\n",
    "    reward = torch.tensor(reward, dtype=torch.float)[:, None]\n",
    "    done = torch.tensor(done, dtype=torch.uint8)[:, None]  # Boolean\n",
    "\n",
    "    # compute the q value\n",
    "    q_val = compute_q_vals(Q, state, action)\n",
    "    with torch.no_grad():  # Don't compute gradient info for the target (semi-gradient)\n",
    "        target = compute_targets(Q, reward, next_state, done, discount_factor)\n",
    "\n",
    "    # loss is measured from error between current and newly expected Q values\n",
    "    loss = F.smooth_l1_loss(q_val, target)\n",
    "\n",
    "    # backpropagation of loss to Neural Network (PyTorch magic)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return (\n",
    "        loss.item()\n",
    "    )  # Returns a Python scalar, and releases history (similar to .detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b060b822eec4282f",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4670529067516327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thesofakillers/miniconda3/envs/rl/lib/python3.7/site-packages/ipykernel_launcher.py:49: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1659484744261/work/torch/csrc/utils/tensor_new.cpp:204.)\n"
     ]
    }
   ],
   "source": [
    "# You may want to test your functions individually, but after you do so lets see if the method train works.\n",
    "batch_size = 64\n",
    "discount_factor = 0.8\n",
    "learn_rate = 1e-3\n",
    "# Simple gradient descent may take long, so we will use Adam\n",
    "optimizer = optim.Adam(Q_net.parameters(), learn_rate)\n",
    "\n",
    "# We need a larger memory, fill with dummy data\n",
    "transition = memory.sample(1)[0]\n",
    "memory = ReplayMemory(10 * batch_size)\n",
    "for i in range(batch_size):\n",
    "    memory.push(transition)\n",
    "\n",
    "# Now let's see if it works\n",
    "loss = train(Q_net, memory, optimizer, batch_size, discount_factor)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3eafd0ab49103f3b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.5 Put it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-36b8a04b393d8104",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now that you have implemented the training step, you should be able to put everything together. Implement the function `run_episodes` that runs a number of episodes of DQN training. It should return the durations (e.g. number of steps) of each episode. Note: we pass the train function as an argument such that we can swap it for a different training step later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-540a7d50ecc1d046",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to dqn_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a dqn_autograde.py\n",
    "\n",
    "\n",
    "def run_episodes(\n",
    "    train, Q, policy, memory, env, num_episodes, batch_size, discount_factor, learn_rate\n",
    "):\n",
    "\n",
    "    optimizer = optim.Adam(Q.parameters(), learn_rate)\n",
    "\n",
    "    global_steps = (\n",
    "        0  # Count the steps (do not reset at episode start, to compute epsilon)\n",
    "    )\n",
    "    episode_durations = []  #\n",
    "    for i in range(num_episodes):\n",
    "        state = env.reset()\n",
    "\n",
    "        steps = 0\n",
    "        while True:\n",
    "            # YOUR CODE HERE\n",
    "            policy.set_epsilon(get_epsilon(global_steps))\n",
    "            action = policy.sample_action(state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            steps += 1\n",
    "            global_steps += 1\n",
    "            memory.push((state, action, reward, next_state, done))\n",
    "            loss = train(Q, memory, optimizer, batch_size, discount_factor)\n",
    "            if done:\n",
    "                if i % 10 == 0:\n",
    "                    print(\n",
    "                        \"{2} Episode {0} finished after {1} steps\".format(\n",
    "                            i, steps, \"\\033[92m\" if steps >= 195 else \"\\033[99m\"\n",
    "                        )\n",
    "                    )\n",
    "                episode_durations.append(steps)\n",
    "                # plot_durations()\n",
    "                break\n",
    "            state = next_state\n",
    "    return episode_durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[99m Episode 0 finished after 8 steps\n",
      "\u001b[99m Episode 10 finished after 17 steps\n",
      "\u001b[99m Episode 20 finished after 12 steps\n",
      "\u001b[99m Episode 30 finished after 10 steps\n",
      "\u001b[99m Episode 40 finished after 68 steps\n",
      "\u001b[99m Episode 50 finished after 77 steps\n",
      "\u001b[99m Episode 60 finished after 110 steps\n",
      "\u001b[99m Episode 70 finished after 159 steps\n",
      "\u001b[92m Episode 80 finished after 223 steps\n",
      "\u001b[92m Episode 90 finished after 259 steps\n"
     ]
    }
   ],
   "source": [
    "# Let's run it!\n",
    "num_episodes = 100\n",
    "batch_size = 64\n",
    "discount_factor = 0.8\n",
    "learn_rate = 1e-3\n",
    "memory = ReplayMemory(10000)\n",
    "num_hidden = 128\n",
    "seed = 42  # This is not randomly chosen\n",
    "\n",
    "# We will seed the algorithm (before initializing QNetwork!) for reproducibility\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "env.seed(seed)\n",
    "\n",
    "Q_net = QNetwork(num_hidden)\n",
    "policy = EpsilonGreedyPolicy(Q_net, 0.05)\n",
    "episode_durations = run_episodes(\n",
    "    train,\n",
    "    Q_net,\n",
    "    policy,\n",
    "    memory,\n",
    "    env,\n",
    "    num_episodes,\n",
    "    batch_size,\n",
    "    discount_factor,\n",
    "    learn_rate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-928ecc11ed5c43d8",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Episode durations per episode')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# And see the results\n",
    "def smooth(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0))\n",
    "    return (cumsum[N:] - cumsum[:-N]) / float(N)\n",
    "\n",
    "\n",
    "plt.plot(smooth(episode_durations, 10))\n",
    "plt.title(\"Episode durations per episode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to test/submit your solution **restart the kernel, run all cells and submit the dqn_autograde.py file into codegrade.**"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "6688a8c017489d5058ae9e383a3204f3c3faa81df517373b54fd93e743f871e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
